{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the store df: (1115, 10)\n",
      "The column names before dropping are : ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'State']\n",
      "Size of the dataset after merging is : (1017209, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = ['rossmann-store-sales/train.csv',\n",
    "             'rossmann-store-sales/test.csv', 'rossmann-store-sales/store.csv', 'rossmann-store-sales/store_states.csv']\n",
    "store_df = pd.read_csv(file_path[2], low_memory=False)\n",
    "store_states_df = pd.read_csv(file_path[3], low_memory=False)\n",
    "\n",
    "print(f\"Size of the store df: {store_df.shape}\")\n",
    "\n",
    "train_df = pd.read_csv(file_path[0], low_memory=False) # split this into test train for validation ++ we may also need to reverse the order of the data\n",
    "test_df = pd.read_csv(file_path[1], low_memory=False)\n",
    "train_df = pd.merge(train_df, store_df, how=\"inner\", on=\"Store\") #  one thing to note is that when they pre process data, they keep the store and test data separate, \n",
    "test_df = pd.merge(test_df, store_df, how=\"inner\", on=\"Store\")\n",
    "train_df = pd.merge(train_df, store_states_df, how=\"inner\", on=\"Store\")\n",
    "test_df = pd.merge(test_df, store_states_df, how=\"inner\", on=\"Store\")\n",
    "\n",
    "print(f\"The column names before dropping are : {train_df.columns.tolist()}\")\n",
    "print(f\"Size of the dataset after merging is : {train_df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "train_df['Year'], train_df['Month'], train_df['Day'] = train_df['Date'].dt.year.values, train_df['Date'].dt.month.values, train_df['Date'].dt.day.values\n",
    "train_df.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "# helper function to replace nan values if any\n",
    "def replace_nan_values(dataframe, replace_with='0'):\n",
    "    return dataframe.fillna(replace_with) \n",
    "\n",
    "replace_nan_values(train_df)\n",
    "# train_df.fillna('0', inplace=True) # for some reason doing this throws deprecated warning? Even tho its literaaly the same thing as above\n",
    "\n",
    "train_df = train_df[train_df[\"Sales\"]!=\"0\"]\n",
    "train_df = train_df[train_df[\"Open\"]!=\"\"]\n",
    "cols_to_drop = ['Open', 'StateHoliday', 'SchoolHoliday', 'CompetitionOpenSinceMonth', 'StoreType', 'Assortment', 'PromoInterval', 'Promo2SinceWeek', 'Promo2SinceYear', 'Promo2', 'CompetitionOpenSinceYear', 'CompetitionDistance', 'Customers']\n",
    "\n",
    "train_df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_data_y = pd.DataFrame(train_df['Sales'])\n",
    "train_data_x = train_df.drop(['Sales'], axis=1)\n",
    "\n",
    "for feature in train_data_x.columns:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    train_data_x.loc[:,feature] = label_encoder.fit_transform(train_data_x[feature].astype(str).fillna(\"0\").values)\n",
    "\n",
    "train_data_x = train_data_x.astype(int)\n",
    "\n",
    "##############################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Promo</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013294</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544295</th>\n",
       "      <td>668</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28725</th>\n",
       "      <td>361</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380798</th>\n",
       "      <td>470</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281523</th>\n",
       "      <td>351</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685405</th>\n",
       "      <td>842</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214608</th>\n",
       "      <td>269</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387847</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137242</th>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store  DayOfWeek  Promo  State  Year  Month  Day\n",
       "1013294    126          0      1      6     0      7   19\n",
       "544295     668          4      1      7     1     10   14\n",
       "28725      361          6      0      2     2      7    8\n",
       "380798     470          2      0      6     2      5   17\n",
       "281523     351          4      0      8     0      9    3\n",
       "23706      294          3      0     11     0     10   14\n",
       "685405     842          5      0      6     1      0   25\n",
       "214608     269          4      1      0     1      9   25\n",
       "387847     478          0      0      6     0      8   16\n",
       "137242     175          6      0      6     2      5    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x.sample(10) # shows random 10 instead of first ten like head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017209, 7)\n",
      "(1017209, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x.shape)\n",
    "print(train_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingNetwork(\n",
      "  (embedding): Embedding(100, 50)\n",
      "  (fc): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the neural network class\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, output_size):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) # Embedding layer. The size of the embedding is arbitrary, but the number of rows must match the size of the vocabulary/number of categories. The number of columns is the size of the embedding vectors. \n",
    "        self.fc = nn.Linear(embedding_size, output_size) # Fully connected layer or the dense layer. This is where the actual computation happens. The actual NN. We pass the output of the embedding layer to the fully connected layer. The fully connected layer is a linear layer, which means that it performs a linear transformation on the input. The input size is the size of the embedding vectors, and the output size is the size of the output.\n",
    "\n",
    "    def forward(self, x): # The forward method is called when we pass data through the network.\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.mean(dim=1)  # Average the embeddings\n",
    "        output = self.fc(embedded)\n",
    "        return output\n",
    "\n",
    "# not yet defined. This is just arbitrary\n",
    "\n",
    "# Create an instance of the neural network\n",
    "input_size = 100  # Size of the input vocabulary\n",
    "embedding_size = 50  # Size of the embedding vectors\n",
    "output_size = 10  # Size of the output\n",
    "model = EmbeddingNetwork(input_size, embedding_size, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
      "[{'Store': '1115', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1114', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1113', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}]\n",
      "['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "['Store', 'State']\n",
      "[{'Store': '1', 'StoreType': 'c', 'Assortment': 'a', 'CompetitionDistance': '1270', 'CompetitionOpenSinceMonth': '9', 'CompetitionOpenSinceYear': '2008', 'Promo2': '0', 'Promo2SinceWeek': '0', 'Promo2SinceYear': '0', 'PromoInterval': '0', 'State': 'HE'}, {'Store': '2', 'StoreType': 'a', 'Assortment': 'a', 'CompetitionDistance': '570', 'CompetitionOpenSinceMonth': '11', 'CompetitionOpenSinceYear': '2007', 'Promo2': '1', 'Promo2SinceWeek': '13', 'Promo2SinceYear': '2010', 'PromoInterval': 'Jan,Apr,Jul,Oct', 'State': 'TH'}]\n",
      "Number of train datapoints:  844338\n",
      "46 41551\n",
      "['1' '1097' '2' '0' '2013' '1' '1' 'RP']\n",
      "[  0 109   1   0   0   0   0   7]\n",
      "[  0 109   1   0   0   0   0   7] 5961\n"
     ]
    }
   ],
   "source": [
    "# this is their code. They converted each row into a dictionary and then converted dataset into a list of dictionaries\n",
    "\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "\n",
    "def csv2dicts(csvfile):\n",
    "    data = []\n",
    "    keys = []\n",
    "    for row_index, row in enumerate(csvfile):\n",
    "        if row_index == 0:\n",
    "            keys = row\n",
    "            print(row)\n",
    "            continue\n",
    "        # if row_index % 10000 == 0:\n",
    "        #     print(row_index)\n",
    "        data.append({key: value for key, value in zip(keys, row)})\n",
    "    return data\n",
    "\n",
    "\n",
    "def set_nan_as_string(data, replace_str='0'):\n",
    "    for i, x in enumerate(data):\n",
    "        for key, value in x.items():\n",
    "            if value == '':\n",
    "                x[key] = replace_str\n",
    "        data[i] = x\n",
    "\n",
    "\n",
    "train_data = \"rossmann-store-sales/train.csv\"\n",
    "store_data = \"rossmann-store-sales/store.csv\"\n",
    "store_states = 'rossmann-store-sales/store_states.csv'\n",
    "\n",
    "with open(train_data) as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    with open('train_data.pickle', 'wb') as f:\n",
    "        data = csv2dicts(data)\n",
    "        data = data[::-1]\n",
    "        pickle.dump(data, f, -1)\n",
    "        print(data[:3])\n",
    "\n",
    "\n",
    "with open(store_data) as csvfile, open(store_states) as csvfile2:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    state_data = csv.reader(csvfile2, delimiter=',')\n",
    "    with open('store_data.pickle', 'wb') as f:\n",
    "        data = csv2dicts(data)\n",
    "        state_data = csv2dicts(state_data)\n",
    "        set_nan_as_string(data)\n",
    "        for index, val in enumerate(data):\n",
    "            state = state_data[index]\n",
    "            val['State'] = state['State']\n",
    "            data[index] = val\n",
    "        pickle.dump(data, f, -1)\n",
    "        print(data[:2])\n",
    "        \n",
    "        \n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "with open('train_data.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    num_records = len(train_data)\n",
    "with open('store_data.pickle', 'rb') as f:\n",
    "    store_data = pickle.load(f)\n",
    "\n",
    "\n",
    "def feature_list(record):\n",
    "    dt = datetime.strptime(record['Date'], '%Y-%m-%d')\n",
    "    store_index = int(record['Store'])\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    day_of_week = int(record['DayOfWeek'])\n",
    "    try:\n",
    "        store_open = int(record['Open'])\n",
    "    except:\n",
    "        store_open = 1\n",
    "\n",
    "    promo = int(record['Promo'])\n",
    "\n",
    "    return [store_open,  # they only kept these columns\n",
    "            store_index,\n",
    "            day_of_week,\n",
    "            promo,\n",
    "            year,\n",
    "            month,\n",
    "            day,\n",
    "            store_data[store_index - 1]['State']\n",
    "            ]\n",
    "\n",
    "\n",
    "train_data_X = []\n",
    "train_data_y = []\n",
    "\n",
    "for record in train_data:\n",
    "    if record['Sales'] != '0' and record['Open'] != '':\n",
    "        fl = feature_list(record)\n",
    "        train_data_X.append(fl)\n",
    "        train_data_y.append(int(record['Sales']))\n",
    "print(\"Number of train datapoints: \", len(train_data_y))\n",
    "\n",
    "print(min(train_data_y), max(train_data_y))\n",
    "full_X = train_data_X\n",
    "full_X = np.array(full_X)\n",
    "train_data_X = np.array(train_data_X)\n",
    "print(train_data_X[0])\n",
    "les = []\n",
    "for i in range(train_data_X.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(full_X[:, i])\n",
    "    les.append(le)\n",
    "    train_data_X[:, i] = le.transform(train_data_X[:, i])\n",
    "\n",
    "with open('les.pickle', 'wb') as f:\n",
    "    pickle.dump(les, f, -1)\n",
    "\n",
    "train_data_X = train_data_X.astype(int)\n",
    "train_data_y = np.array(train_data_y)\n",
    "print(train_data_X[0])\n",
    "with open('feature_train_data.pickle', 'wb') as f:\n",
    "    pickle.dump((train_data_X, train_data_y), f, -1)\n",
    "    print(train_data_X[0], train_data_y[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
