{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
      "[{'Store': '1115', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1114', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1113', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}]\n",
      "['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "['Store', 'State']\n",
      "[{'Store': '1', 'StoreType': 'c', 'Assortment': 'a', 'CompetitionDistance': '1270', 'CompetitionOpenSinceMonth': '9', 'CompetitionOpenSinceYear': '2008', 'Promo2': '0', 'Promo2SinceWeek': '0', 'Promo2SinceYear': '0', 'PromoInterval': '0', 'State': 'HE'}, {'Store': '2', 'StoreType': 'a', 'Assortment': 'a', 'CompetitionDistance': '570', 'CompetitionOpenSinceMonth': '11', 'CompetitionOpenSinceYear': '2007', 'Promo2': '1', 'Promo2SinceWeek': '13', 'Promo2SinceYear': '2010', 'PromoInterval': 'Jan,Apr,Jul,Oct', 'State': 'TH'}]\n",
      "Number of train datapoints:  844338\n",
      "46 41551\n",
      "['1' '1097' '2' '0' '2013' '1' '1' 'RP']\n",
      "[  0 109   1   0   0   0   0   7]\n",
      "[  0 109   1   0   0   0   0   7] 5961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "\n",
    "def csv2dicts(csvfile):\n",
    "    data = []\n",
    "    keys = []\n",
    "    for row_index, row in enumerate(csvfile):\n",
    "        if row_index == 0:\n",
    "            keys = row\n",
    "            print(row)\n",
    "            continue\n",
    "        # if row_index % 10000 == 0:\n",
    "        #     print(row_index)\n",
    "        data.append({key: value for key, value in zip(keys, row)})\n",
    "    return data\n",
    "\n",
    "\n",
    "def set_nan_as_string(data, replace_str='0'):\n",
    "    for i, x in enumerate(data):\n",
    "        for key, value in x.items():\n",
    "            if value == '':\n",
    "                x[key] = replace_str\n",
    "        data[i] = x\n",
    "\n",
    "\n",
    "train_data = \"rossmann-store-sales/train.csv\"\n",
    "store_data = \"rossmann-store-sales/store.csv\"\n",
    "store_states = 'rossmann-store-sales/store_states.csv'\n",
    "\n",
    "with open(train_data) as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    with open('train_data.pickle', 'wb') as f:\n",
    "        data = csv2dicts(data)\n",
    "        data = data[::-1]\n",
    "        pickle.dump(data, f, -1)\n",
    "        print(data[:3])\n",
    "\n",
    "\n",
    "with open(store_data) as csvfile, open(store_states) as csvfile2:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    state_data = csv.reader(csvfile2, delimiter=',')\n",
    "    with open('store_data.pickle', 'wb') as f:\n",
    "        data = csv2dicts(data)\n",
    "        state_data = csv2dicts(state_data)\n",
    "        set_nan_as_string(data)\n",
    "        for index, val in enumerate(data):\n",
    "            state = state_data[index]\n",
    "            val['State'] = state['State']\n",
    "            data[index] = val\n",
    "        pickle.dump(data, f, -1)\n",
    "        print(data[:2])\n",
    "        \n",
    "        \n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "with open('train_data.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    num_records = len(train_data)\n",
    "with open('store_data.pickle', 'rb') as f:\n",
    "    store_data = pickle.load(f)\n",
    "\n",
    "\n",
    "def feature_list(record):\n",
    "    dt = datetime.strptime(record['Date'], '%Y-%m-%d')\n",
    "    store_index = int(record['Store'])\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    day_of_week = int(record['DayOfWeek'])\n",
    "    try:\n",
    "        store_open = int(record['Open'])\n",
    "    except:\n",
    "        store_open = 1\n",
    "\n",
    "    promo = int(record['Promo'])\n",
    "\n",
    "    return [store_open,  # they only kept these columns\n",
    "            store_index,\n",
    "            day_of_week,\n",
    "            promo,\n",
    "            year,\n",
    "            month,\n",
    "            day,\n",
    "            store_data[store_index - 1]['State']\n",
    "            ]\n",
    "\n",
    "\n",
    "train_data_X = []\n",
    "train_data_y = []\n",
    "\n",
    "for record in train_data:\n",
    "    if record['Sales'] != '0' and record['Open'] != '':\n",
    "        fl = feature_list(record)\n",
    "        train_data_X.append(fl)\n",
    "        train_data_y.append(int(record['Sales']))\n",
    "print(\"Number of train datapoints: \", len(train_data_y))\n",
    "\n",
    "print(min(train_data_y), max(train_data_y))\n",
    "full_X = train_data_X\n",
    "full_X = np.array(full_X)\n",
    "train_data_X = np.array(train_data_X)\n",
    "print(train_data_X[0])\n",
    "les = []\n",
    "for i in range(train_data_X.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(full_X[:, i])\n",
    "    les.append(le)\n",
    "    train_data_X[:, i] = le.transform(train_data_X[:, i])\n",
    "\n",
    "with open('les.pickle', 'wb') as f:\n",
    "    pickle.dump(les, f, -1)\n",
    "\n",
    "train_data_X = train_data_X.astype(int)\n",
    "train_data_y = np.array(train_data_y)\n",
    "print(train_data_X[0])\n",
    "with open('feature_train_data.pickle', 'wb') as f:\n",
    "    pickle.dump((train_data_X, train_data_y), f, -1)\n",
    "    print(train_data_X[0], train_data_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(123)\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model as KerasModel\n",
    "from keras.layers import Input, Dense, Activation, Reshape\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def embed_features(X, saved_embeddings_fname):\n",
    "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
    "    f_embeddings = open(saved_embeddings_fname, \"rb\")\n",
    "    embeddings = pickle.load(f_embeddings)\n",
    "\n",
    "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5}\n",
    "    X_embedded = []\n",
    "\n",
    "    (num_records, num_features) = X.shape\n",
    "    for record in X:\n",
    "        embedded_features = []\n",
    "        for i, feat in enumerate(record):\n",
    "            feat = int(feat)\n",
    "            if i not in index_embedding_mapping.keys():\n",
    "                embedded_features += [feat]\n",
    "            else:\n",
    "                embedding_index = index_embedding_mapping[i]\n",
    "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
    "\n",
    "        X_embedded.append(embedded_features)\n",
    "\n",
    "    return numpy.array(X_embedded)\n",
    "\n",
    "\n",
    "def split_features(X):\n",
    "    X_list = []\n",
    "\n",
    "    store_index = X[..., [1]]\n",
    "    X_list.append(store_index)\n",
    "\n",
    "    day_of_week = X[..., [2]]\n",
    "    X_list.append(day_of_week)\n",
    "\n",
    "    promo = X[..., [3]]\n",
    "    X_list.append(promo)\n",
    "\n",
    "    year = X[..., [4]]\n",
    "    X_list.append(year)\n",
    "\n",
    "    month = X[..., [5]]\n",
    "    X_list.append(month)\n",
    "\n",
    "    day = X[..., [6]]\n",
    "    X_list.append(day)\n",
    "\n",
    "    State = X[..., [7]]\n",
    "    X_list.append(State)\n",
    "\n",
    "    return X_list\n",
    "\n",
    "\n",
    "class NN_with_EntityEmbedding(Model):\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
    "        self.max_log_y = max(numpy.max(numpy.log(y_train)), numpy.max(numpy.log(y_val)))\n",
    "        self.__build_keras_model()\n",
    "        self.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    def preprocessing(self, X):\n",
    "        X_list = split_features(X)\n",
    "        print(len(X_list))\n",
    "        print(X_list[0].shape)\n",
    "        \n",
    "        print(X_list[:3])\n",
    "        return X_list\n",
    "\n",
    "    def __build_keras_model(self):\n",
    "        input_store = Input(shape=(1,))\n",
    "        output_store = Embedding(1115, 10, name='store_embedding')(input_store)\n",
    "        output_store = Reshape(target_shape=(10,))(output_store)\n",
    "\n",
    "        input_dow = Input(shape=(1,))\n",
    "        output_dow = Embedding(7, 6, name='dow_embedding')(input_dow)\n",
    "        output_dow = Reshape(target_shape=(6,))(output_dow)\n",
    "\n",
    "        input_promo = Input(shape=(1,))\n",
    "        output_promo = Dense(1)(input_promo)\n",
    "\n",
    "        input_year = Input(shape=(1,))\n",
    "        output_year = Embedding(3, 2, name='year_embedding')(input_year)\n",
    "        output_year = Reshape(target_shape=(2,))(output_year)\n",
    "\n",
    "        input_month = Input(shape=(1,))\n",
    "        output_month = Embedding(12, 6, name='month_embedding')(input_month)\n",
    "        output_month = Reshape(target_shape=(6,))(output_month)\n",
    "\n",
    "        input_day = Input(shape=(1,))\n",
    "        output_day = Embedding(31, 10, name='day_embedding')(input_day)\n",
    "        output_day = Reshape(target_shape=(10,))(output_day)\n",
    "\n",
    "        input_germanstate = Input(shape=(1,))\n",
    "        output_germanstate = Embedding(12, 6, name='state_embedding')(input_germanstate)\n",
    "        output_germanstate = Reshape(target_shape=(6,))(output_germanstate)\n",
    "\n",
    "        input_model = [input_store, input_dow, input_promo,\n",
    "                       input_year, input_month, input_day, input_germanstate]\n",
    "\n",
    "        output_embeddings = [output_store, output_dow, output_promo,\n",
    "                             output_year, output_month, output_day, output_germanstate]\n",
    "\n",
    "        output_model = Concatenate()(output_embeddings)\n",
    "        output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
    "        output_model = Activation('relu')(output_model)\n",
    "        output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
    "        output_model = Activation('relu')(output_model)\n",
    "        output_model = Dense(1)(output_model)\n",
    "        output_model = Activation('sigmoid')(output_model)\n",
    "\n",
    "        self.model = KerasModel(inputs=input_model, outputs=output_model)\n",
    "\n",
    "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "    def _val_for_fit(self, val):\n",
    "        val = numpy.log(val) / self.max_log_y\n",
    "        return val\n",
    "\n",
    "    def _val_for_pred(self, val):\n",
    "        return numpy.exp(val * self.max_log_y)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        self.preprocessing(X_train)\n",
    "        self.model.fit(self.preprocessing(X_train), self._val_for_fit(y_train),\n",
    "                       validation_data=(self.preprocessing(X_val), self._val_for_fit(y_val)),\n",
    "                       epochs=self.epochs, batch_size=128,\n",
    "                       # callbacks=[self.checkpointer],\n",
    "                       )\n",
    "        # self.model.load_weights('best_model_weights.hdf5')\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        features = self.preprocessing(features)\n",
    "        result = self.model.predict(features).flatten()\n",
    "        return self._val_for_pred(result)\n",
    "\n",
    "\n",
    "class NN(Model):\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
    "        self.max_log_y = max(numpy.max(numpy.log(y_train)), numpy.max(numpy.log(y_val)))\n",
    "        self.__build_keras_model()\n",
    "        self.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    def __build_keras_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(1000, kernel_initializer=\"uniform\", input_dim=1183))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(500, kernel_initializer=\"uniform\"))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "\n",
    "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "    def _val_for_fit(self, val):\n",
    "        val = numpy.log(val) / self.max_log_y\n",
    "        return val\n",
    "\n",
    "    def _val_for_pred(self, val):\n",
    "        return numpy.exp(val * self.max_log_y)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        self.model.fit(X_train, self._val_for_fit(y_train),\n",
    "                       validation_data=(X_val, self._val_for_fit(y_val)),\n",
    "                       epochs=self.epochs, batch_size=128,\n",
    "                       # callbacks=[self.checkpointer],\n",
    "                       )\n",
    "        # self.model.load_weights('best_model_weights.hdf5')\n",
    "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
    "\n",
    "    def guess(self, features):\n",
    "        result = self.model.predict(features).flatten()\n",
    "        return self._val_for_pred(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used for training: 200\n",
      "(200, 8)\n",
      "(200,)\n",
      "[[   0  467    5    0    0    1   18    7]\n",
      " [   0  940    3    0    0    0   24    9]\n",
      " [   0  272    5    0    0    0   10    6]\n",
      " [   0 1022    0    1    0    9   21    2]\n",
      " [   0  257    1    1    0    9   23    4]]\n",
      "Fitting NN_with_EntityEmbedding...\n",
      "7\n",
      "(200, 1)\n",
      "[array([[ 467],\n",
      "       [ 940],\n",
      "       [ 272],\n",
      "       [1022],\n",
      "       [ 257],\n",
      "       [ 856],\n",
      "       [ 229],\n",
      "       [ 486],\n",
      "       [ 915],\n",
      "       [1073],\n",
      "       [  69],\n",
      "       [ 804],\n",
      "       [ 385],\n",
      "       [ 354],\n",
      "       [  37],\n",
      "       [ 333],\n",
      "       [ 725],\n",
      "       [ 139],\n",
      "       [ 531],\n",
      "       [ 340],\n",
      "       [ 939],\n",
      "       [ 808],\n",
      "       [ 103],\n",
      "       [ 984],\n",
      "       [ 215],\n",
      "       [ 503],\n",
      "       [ 305],\n",
      "       [ 753],\n",
      "       [ 116],\n",
      "       [  71],\n",
      "       [1029],\n",
      "       [ 670],\n",
      "       [ 929],\n",
      "       [ 917],\n",
      "       [ 722],\n",
      "       [ 847],\n",
      "       [1021],\n",
      "       [ 854],\n",
      "       [ 312],\n",
      "       [ 604],\n",
      "       [ 704],\n",
      "       [ 601],\n",
      "       [ 320],\n",
      "       [  21],\n",
      "       [ 148],\n",
      "       [ 452],\n",
      "       [ 126],\n",
      "       [ 349],\n",
      "       [ 806],\n",
      "       [ 124],\n",
      "       [ 230],\n",
      "       [ 276],\n",
      "       [ 535],\n",
      "       [ 336],\n",
      "       [1054],\n",
      "       [ 687],\n",
      "       [ 298],\n",
      "       [ 569],\n",
      "       [ 231],\n",
      "       [ 646],\n",
      "       [  35],\n",
      "       [ 668],\n",
      "       [ 630],\n",
      "       [ 265],\n",
      "       [ 371],\n",
      "       [ 443],\n",
      "       [1112],\n",
      "       [ 533],\n",
      "       [ 976],\n",
      "       [ 663],\n",
      "       [ 908],\n",
      "       [ 611],\n",
      "       [ 446],\n",
      "       [ 974],\n",
      "       [ 343],\n",
      "       [ 887],\n",
      "       [  52],\n",
      "       [ 597],\n",
      "       [ 756],\n",
      "       [1040],\n",
      "       [ 905],\n",
      "       [ 122],\n",
      "       [ 762],\n",
      "       [  54],\n",
      "       [ 369],\n",
      "       [ 988],\n",
      "       [ 662],\n",
      "       [ 585],\n",
      "       [ 574],\n",
      "       [ 667],\n",
      "       [ 894],\n",
      "       [ 617],\n",
      "       [ 408],\n",
      "       [ 420],\n",
      "       [ 981],\n",
      "       [1063],\n",
      "       [ 478],\n",
      "       [ 747],\n",
      "       [ 943],\n",
      "       [ 172],\n",
      "       [ 136],\n",
      "       [ 162],\n",
      "       [ 260],\n",
      "       [ 817],\n",
      "       [ 992],\n",
      "       [ 805],\n",
      "       [ 285],\n",
      "       [ 879],\n",
      "       [ 324],\n",
      "       [ 619],\n",
      "       [ 571],\n",
      "       [ 117],\n",
      "       [ 223],\n",
      "       [1081],\n",
      "       [   1],\n",
      "       [ 852],\n",
      "       [ 462],\n",
      "       [ 478],\n",
      "       [ 903],\n",
      "       [ 221],\n",
      "       [ 273],\n",
      "       [  93],\n",
      "       [ 282],\n",
      "       [ 849],\n",
      "       [ 687],\n",
      "       [  37],\n",
      "       [ 584],\n",
      "       [ 185],\n",
      "       [ 586],\n",
      "       [ 581],\n",
      "       [ 606],\n",
      "       [ 980],\n",
      "       [  46],\n",
      "       [  62],\n",
      "       [1068],\n",
      "       [ 729],\n",
      "       [ 220],\n",
      "       [ 599],\n",
      "       [ 539],\n",
      "       [ 451],\n",
      "       [ 502],\n",
      "       [  94],\n",
      "       [ 470],\n",
      "       [ 315],\n",
      "       [ 736],\n",
      "       [   6],\n",
      "       [ 495],\n",
      "       [ 624],\n",
      "       [ 311],\n",
      "       [ 409],\n",
      "       [ 826],\n",
      "       [1106],\n",
      "       [ 221],\n",
      "       [ 841],\n",
      "       [ 922],\n",
      "       [ 132],\n",
      "       [ 376],\n",
      "       [1109],\n",
      "       [ 176],\n",
      "       [ 562],\n",
      "       [ 945],\n",
      "       [ 898],\n",
      "       [ 635],\n",
      "       [ 195],\n",
      "       [ 798],\n",
      "       [ 430],\n",
      "       [ 783],\n",
      "       [ 938],\n",
      "       [1033],\n",
      "       [  62],\n",
      "       [ 694],\n",
      "       [ 342],\n",
      "       [ 525],\n",
      "       [ 855],\n",
      "       [ 639],\n",
      "       [   1],\n",
      "       [ 635],\n",
      "       [ 671],\n",
      "       [ 501],\n",
      "       [ 741],\n",
      "       [ 284],\n",
      "       [ 738],\n",
      "       [1102],\n",
      "       [ 909],\n",
      "       [ 560],\n",
      "       [ 226],\n",
      "       [ 684],\n",
      "       [ 421],\n",
      "       [ 978],\n",
      "       [ 294],\n",
      "       [ 187],\n",
      "       [ 381],\n",
      "       [ 730],\n",
      "       [1109],\n",
      "       [  61],\n",
      "       [ 972],\n",
      "       [ 292],\n",
      "       [ 588],\n",
      "       [ 799],\n",
      "       [ 148]]), array([[5],\n",
      "       [3],\n",
      "       [5],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [5],\n",
      "       [1],\n",
      "       [4],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [3],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [2],\n",
      "       [2],\n",
      "       [0],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [4],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [2],\n",
      "       [3],\n",
      "       [1],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [1],\n",
      "       [6],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [5],\n",
      "       [1],\n",
      "       [5],\n",
      "       [3],\n",
      "       [4],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [3],\n",
      "       [2],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [4],\n",
      "       [5],\n",
      "       [3],\n",
      "       [5],\n",
      "       [1],\n",
      "       [3],\n",
      "       [0],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [2],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [1],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [5],\n",
      "       [4],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [0],\n",
      "       [5],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [0],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [4],\n",
      "       [3],\n",
      "       [5],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [5],\n",
      "       [0],\n",
      "       [0],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [5],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [5],\n",
      "       [5],\n",
      "       [3],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [0],\n",
      "       [0],\n",
      "       [3],\n",
      "       [3],\n",
      "       [0],\n",
      "       [1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [5],\n",
      "       [5],\n",
      "       [3],\n",
      "       [1],\n",
      "       [1],\n",
      "       [4],\n",
      "       [3],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4]]), array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]])]\n",
      "7\n",
      "(200, 1)\n",
      "[array([[ 467],\n",
      "       [ 940],\n",
      "       [ 272],\n",
      "       [1022],\n",
      "       [ 257],\n",
      "       [ 856],\n",
      "       [ 229],\n",
      "       [ 486],\n",
      "       [ 915],\n",
      "       [1073],\n",
      "       [  69],\n",
      "       [ 804],\n",
      "       [ 385],\n",
      "       [ 354],\n",
      "       [  37],\n",
      "       [ 333],\n",
      "       [ 725],\n",
      "       [ 139],\n",
      "       [ 531],\n",
      "       [ 340],\n",
      "       [ 939],\n",
      "       [ 808],\n",
      "       [ 103],\n",
      "       [ 984],\n",
      "       [ 215],\n",
      "       [ 503],\n",
      "       [ 305],\n",
      "       [ 753],\n",
      "       [ 116],\n",
      "       [  71],\n",
      "       [1029],\n",
      "       [ 670],\n",
      "       [ 929],\n",
      "       [ 917],\n",
      "       [ 722],\n",
      "       [ 847],\n",
      "       [1021],\n",
      "       [ 854],\n",
      "       [ 312],\n",
      "       [ 604],\n",
      "       [ 704],\n",
      "       [ 601],\n",
      "       [ 320],\n",
      "       [  21],\n",
      "       [ 148],\n",
      "       [ 452],\n",
      "       [ 126],\n",
      "       [ 349],\n",
      "       [ 806],\n",
      "       [ 124],\n",
      "       [ 230],\n",
      "       [ 276],\n",
      "       [ 535],\n",
      "       [ 336],\n",
      "       [1054],\n",
      "       [ 687],\n",
      "       [ 298],\n",
      "       [ 569],\n",
      "       [ 231],\n",
      "       [ 646],\n",
      "       [  35],\n",
      "       [ 668],\n",
      "       [ 630],\n",
      "       [ 265],\n",
      "       [ 371],\n",
      "       [ 443],\n",
      "       [1112],\n",
      "       [ 533],\n",
      "       [ 976],\n",
      "       [ 663],\n",
      "       [ 908],\n",
      "       [ 611],\n",
      "       [ 446],\n",
      "       [ 974],\n",
      "       [ 343],\n",
      "       [ 887],\n",
      "       [  52],\n",
      "       [ 597],\n",
      "       [ 756],\n",
      "       [1040],\n",
      "       [ 905],\n",
      "       [ 122],\n",
      "       [ 762],\n",
      "       [  54],\n",
      "       [ 369],\n",
      "       [ 988],\n",
      "       [ 662],\n",
      "       [ 585],\n",
      "       [ 574],\n",
      "       [ 667],\n",
      "       [ 894],\n",
      "       [ 617],\n",
      "       [ 408],\n",
      "       [ 420],\n",
      "       [ 981],\n",
      "       [1063],\n",
      "       [ 478],\n",
      "       [ 747],\n",
      "       [ 943],\n",
      "       [ 172],\n",
      "       [ 136],\n",
      "       [ 162],\n",
      "       [ 260],\n",
      "       [ 817],\n",
      "       [ 992],\n",
      "       [ 805],\n",
      "       [ 285],\n",
      "       [ 879],\n",
      "       [ 324],\n",
      "       [ 619],\n",
      "       [ 571],\n",
      "       [ 117],\n",
      "       [ 223],\n",
      "       [1081],\n",
      "       [   1],\n",
      "       [ 852],\n",
      "       [ 462],\n",
      "       [ 478],\n",
      "       [ 903],\n",
      "       [ 221],\n",
      "       [ 273],\n",
      "       [  93],\n",
      "       [ 282],\n",
      "       [ 849],\n",
      "       [ 687],\n",
      "       [  37],\n",
      "       [ 584],\n",
      "       [ 185],\n",
      "       [ 586],\n",
      "       [ 581],\n",
      "       [ 606],\n",
      "       [ 980],\n",
      "       [  46],\n",
      "       [  62],\n",
      "       [1068],\n",
      "       [ 729],\n",
      "       [ 220],\n",
      "       [ 599],\n",
      "       [ 539],\n",
      "       [ 451],\n",
      "       [ 502],\n",
      "       [  94],\n",
      "       [ 470],\n",
      "       [ 315],\n",
      "       [ 736],\n",
      "       [   6],\n",
      "       [ 495],\n",
      "       [ 624],\n",
      "       [ 311],\n",
      "       [ 409],\n",
      "       [ 826],\n",
      "       [1106],\n",
      "       [ 221],\n",
      "       [ 841],\n",
      "       [ 922],\n",
      "       [ 132],\n",
      "       [ 376],\n",
      "       [1109],\n",
      "       [ 176],\n",
      "       [ 562],\n",
      "       [ 945],\n",
      "       [ 898],\n",
      "       [ 635],\n",
      "       [ 195],\n",
      "       [ 798],\n",
      "       [ 430],\n",
      "       [ 783],\n",
      "       [ 938],\n",
      "       [1033],\n",
      "       [  62],\n",
      "       [ 694],\n",
      "       [ 342],\n",
      "       [ 525],\n",
      "       [ 855],\n",
      "       [ 639],\n",
      "       [   1],\n",
      "       [ 635],\n",
      "       [ 671],\n",
      "       [ 501],\n",
      "       [ 741],\n",
      "       [ 284],\n",
      "       [ 738],\n",
      "       [1102],\n",
      "       [ 909],\n",
      "       [ 560],\n",
      "       [ 226],\n",
      "       [ 684],\n",
      "       [ 421],\n",
      "       [ 978],\n",
      "       [ 294],\n",
      "       [ 187],\n",
      "       [ 381],\n",
      "       [ 730],\n",
      "       [1109],\n",
      "       [  61],\n",
      "       [ 972],\n",
      "       [ 292],\n",
      "       [ 588],\n",
      "       [ 799],\n",
      "       [ 148]]), array([[5],\n",
      "       [3],\n",
      "       [5],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [5],\n",
      "       [1],\n",
      "       [4],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [3],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [2],\n",
      "       [2],\n",
      "       [0],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [4],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [2],\n",
      "       [3],\n",
      "       [1],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [5],\n",
      "       [0],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [1],\n",
      "       [6],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2],\n",
      "       [5],\n",
      "       [1],\n",
      "       [5],\n",
      "       [3],\n",
      "       [4],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [4],\n",
      "       [4],\n",
      "       [3],\n",
      "       [2],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [4],\n",
      "       [5],\n",
      "       [3],\n",
      "       [5],\n",
      "       [1],\n",
      "       [3],\n",
      "       [0],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [2],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [4],\n",
      "       [1],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [5],\n",
      "       [4],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [0],\n",
      "       [5],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [3],\n",
      "       [4],\n",
      "       [0],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [4],\n",
      "       [3],\n",
      "       [5],\n",
      "       [3],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [5],\n",
      "       [0],\n",
      "       [0],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [5],\n",
      "       [1],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3],\n",
      "       [5],\n",
      "       [5],\n",
      "       [3],\n",
      "       [0],\n",
      "       [1],\n",
      "       [2],\n",
      "       [3],\n",
      "       [0],\n",
      "       [0],\n",
      "       [3],\n",
      "       [3],\n",
      "       [0],\n",
      "       [1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [1],\n",
      "       [5],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [5],\n",
      "       [5],\n",
      "       [3],\n",
      "       [1],\n",
      "       [1],\n",
      "       [4],\n",
      "       [3],\n",
      "       [3],\n",
      "       [4],\n",
      "       [4]]), array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]])]\n",
      "7\n",
      "(84434, 1)\n",
      "[array([[ 89],\n",
      "       [ 88],\n",
      "       [ 87],\n",
      "       ...,\n",
      "       [338],\n",
      "       [227],\n",
      "       [  0]]), array([[5],\n",
      "       [5],\n",
      "       [5],\n",
      "       ...,\n",
      "       [4],\n",
      "       [4],\n",
      "       [4]]), array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       ...,\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]])]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3101 - val_loss: 0.2663\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 945ms/step - loss: 0.2458 - val_loss: 0.1944\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 925ms/step - loss: 0.1688 - val_loss: 0.1162\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 903ms/step - loss: 0.1040 - val_loss: 0.0923\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 916ms/step - loss: 0.0873 - val_loss: 0.0682\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 804ms/step - loss: 0.0733 - val_loss: 0.0790\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 950ms/step - loss: 0.0892 - val_loss: 0.0839\n",
      "Epoch 8/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/aisha/Desktop/ML Proj/paper.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting NN_with_EntityEmbedding...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# for i in range(5):\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m models\u001b[39m.\u001b[39mappend(NN_with_EntityEmbedding(X_train, y_train, X_val, y_val))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# models[0].model.preprocessing(X_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# print(\"Fitting NN...\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m# print(\"Fitting XGBoost...\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# models.append(XGBoost(X_train, y_train, X_val, y_val))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mif\u001b[39;00m save_embeddings:\n",
      "\u001b[1;32m/Users/aisha/Desktop/ML Proj/paper.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_log_y \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(numpy\u001b[39m.\u001b[39mmax(numpy\u001b[39m.\u001b[39mlog(y_train)), numpy\u001b[39m.\u001b[39mmax(numpy\u001b[39m.\u001b[39mlog(y_val)))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__build_keras_model()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val)\n",
      "\u001b[1;32m/Users/aisha/Desktop/ML Proj/paper.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=253'>254</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X_train, y_train, X_val, y_val):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessing(X_train)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessing(X_train), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_val_for_fit(y_train),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m                    validation_data\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessing(X_val), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_val_for_fit(y_val)),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m                    \u001b[39m# callbacks=[self.checkpointer],\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=259'>260</a>\u001b[0m                    )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m     \u001b[39m# self.model.load_weights('best_model_weights.hdf5')\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aisha/Desktop/ML%20Proj/paper.ipynb#W3sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mResult on validation data: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(X_val, y_val))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1857\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1858\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1859\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1860\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1861\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1862\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1863\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1864\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1865\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1866\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1867\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1868\u001b[0m )\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2297\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2298\u001b[0m                     data_handler,\n\u001b[1;32m   2299\u001b[0m                     step,\n\u001b[1;32m   2300\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2301\u001b[0m                 )\n\u001b[1;32m   2303\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4109\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    878\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "numpy.random.seed(123)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "train_ratio = 0.9\n",
    "shuffle_data = False\n",
    "one_hot_as_input = False\n",
    "embeddings_as_input = False\n",
    "save_embeddings = True\n",
    "saved_embeddings_fname = \"embeddings.pickle\"  # set save_embeddings to True to create this file\n",
    "\n",
    "f = open('feature_train_data.pickle', 'rb')\n",
    "(X, y) = pickle.load(f)\n",
    "\n",
    "num_records = len(X)\n",
    "train_size = int(train_ratio * num_records)\n",
    "\n",
    "if shuffle_data:\n",
    "    print(\"Using shuffled data\")\n",
    "    sh = numpy.arange(X.shape[0])\n",
    "    numpy.random.shuffle(sh)\n",
    "    X = X[sh]\n",
    "    y = y[sh]\n",
    "\n",
    "if embeddings_as_input:\n",
    "    print(\"Using learned embeddings as input\")\n",
    "    X = embed_features(X, saved_embeddings_fname)\n",
    "\n",
    "if one_hot_as_input:\n",
    "    print(\"Using one-hot encoding as input\")\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    enc.fit(X)\n",
    "    X = enc.transform(X)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "X_val = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_val = y[train_size:]\n",
    "\n",
    "\n",
    "def sample(X, y, n):\n",
    "    '''random samples'''\n",
    "    num_row = X.shape[0]\n",
    "    indices = numpy.random.randint(num_row, size=n)\n",
    "    return X[indices, :], y[indices]\n",
    "\n",
    "\n",
    "X_train, y_train = sample(X_train, y_train, 200)  # Simulate data sparsity\n",
    "# X_train, y_train = sample(X_train, y_train, 200000)  # Simulate data sparsity\n",
    "print(\"Number of samples used for training: \" + str(y_train.shape[0]))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train[:5])\n",
    "models = []\n",
    "\n",
    "print(\"Fitting NN_with_EntityEmbedding...\")\n",
    "# for i in range(5):\n",
    "models.append(NN_with_EntityEmbedding(X_train, y_train, X_val, y_val))\n",
    "\n",
    "if save_embeddings:\n",
    "    model = models[0].model\n",
    "    store_embedding = model.get_layer('store_embedding').get_weights()[0]\n",
    "    dow_embedding = model.get_layer('dow_embedding').get_weights()[0]\n",
    "    year_embedding = model.get_layer('year_embedding').get_weights()[0]\n",
    "    month_embedding = model.get_layer('month_embedding').get_weights()[0]\n",
    "    day_embedding = model.get_layer('day_embedding').get_weights()[0]\n",
    "    german_states_embedding = model.get_layer('state_embedding').get_weights()[0]\n",
    "    with open(saved_embeddings_fname, 'wb') as f:\n",
    "        pickle.dump([store_embedding, dow_embedding, year_embedding,\n",
    "                     month_embedding, day_embedding, german_states_embedding], f, -1)\n",
    "\n",
    "\n",
    "def evaluate_models(models, X, y):\n",
    "    assert(min(y) > 0)\n",
    "    guessed_sales = numpy.array([model.guess(X) for model in models])\n",
    "    mean_sales = guessed_sales.mean(axis=0)\n",
    "    relative_err = numpy.absolute((y - mean_sales) / y)\n",
    "    result = numpy.sum(relative_err) / len(y)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Evaluate combined models...\")\n",
    "print(\"Training error...\")\n",
    "r_train = evaluate_models(models, X_train, y_train)\n",
    "print(r_train)\n",
    "\n",
    "print(\"Validation error...\")\n",
    "r_val = evaluate_models(models, X_val, y_val)\n",
    "print(r_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
